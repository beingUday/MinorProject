{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":13291334,"sourceType":"datasetVersion","datasetId":8423939}],"dockerImageVersionId":31192,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install wfdb --quiet","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-11T14:31:12.372104Z","iopub.execute_input":"2025-11-11T14:31:12.372563Z","iopub.status.idle":"2025-11-11T14:31:19.213100Z","shell.execute_reply.started":"2025-11-11T14:31:12.372534Z","shell.execute_reply":"2025-11-11T14:31:19.211940Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport wfdb\nfrom scipy.signal import butter, filtfilt, medfilt, detrend, iirnotch\nimport os\nimport warnings\nwarnings.filterwarnings('ignore')\nimport pywt\nimport gc","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-11T14:31:19.216223Z","iopub.execute_input":"2025-11-11T14:31:19.217569Z","iopub.status.idle":"2025-11-11T14:31:21.194753Z","shell.execute_reply.started":"2025-11-11T14:31:19.217517Z","shell.execute_reply":"2025-11-11T14:31:21.193569Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"path_A = \"/kaggle/input/minor-project-dataset/set-a/set-a\"\npath_B = \"/kaggle/input/minor-project-dataset/set-b/set-b\"\noutput_train = \"/kaggle/working/final_train.csv\"\noutput_test = \"/kaggle/working/final_test.csv\"\ntrain=[]\ntest=[]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-11T14:31:21.195712Z","iopub.execute_input":"2025-11-11T14:31:21.196218Z","iopub.status.idle":"2025-11-11T14:31:21.202500Z","shell.execute_reply.started":"2025-11-11T14:31:21.196186Z","shell.execute_reply":"2025-11-11T14:31:21.201255Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def detect_ann_type(path, record):\n    for ann_type in ['atr', 'qrs', 'fqrs']:\n        ann_path = os.path.join(path, record + '.' + ann_type)\n        if os.path.isfile(ann_path):\n            return ann_type\n    return None","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-11T14:31:21.204110Z","iopub.execute_input":"2025-11-11T14:31:21.204529Z","iopub.status.idle":"2025-11-11T14:31:21.225592Z","shell.execute_reply.started":"2025-11-11T14:31:21.204496Z","shell.execute_reply":"2025-11-11T14:31:21.224474Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"records_A = sorted(set(os.path.splitext(f)[0] for f in os.listdir(path_A) if f.endswith('.hea')))\nfor record in records_A:\n    ann_type = detect_ann_type(path_A, record)\n    path=os.path.join(path_A, record)\n    recordA = wfdb.rdrecord(path)\n    signalA_df = pd.DataFrame(recordA.p_signal, columns=recordA.sig_name)\n    signalA_df.insert(0, \"record_id\", record)\n    train.append(signalA_df)\n    \nf_train=pd.concat(train)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-11T14:31:21.226885Z","iopub.execute_input":"2025-11-11T14:31:21.227279Z","iopub.status.idle":"2025-11-11T14:31:25.390141Z","shell.execute_reply.started":"2025-11-11T14:31:21.227248Z","shell.execute_reply":"2025-11-11T14:31:25.388966Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"fsA=recordA.fs\nfsA","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-11T14:31:25.391695Z","iopub.execute_input":"2025-11-11T14:31:25.392032Z","iopub.status.idle":"2025-11-11T14:31:25.399578Z","shell.execute_reply.started":"2025-11-11T14:31:25.392004Z","shell.execute_reply":"2025-11-11T14:31:25.398529Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"f_train","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-11T14:31:25.402706Z","iopub.execute_input":"2025-11-11T14:31:25.403016Z","iopub.status.idle":"2025-11-11T14:31:25.443771Z","shell.execute_reply.started":"2025-11-11T14:31:25.402992Z","shell.execute_reply":"2025-11-11T14:31:25.442750Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def bandPass(signal, low, high, fs, order=4):\n    ny=0.5*fs\n    l,h=low/ny,high/ny\n    b,a=butter(4,[l,h], btype=\"band\")\n    return filtfilt(b,a,signal,axis=0)\n    \ndef newBP(signal, lowcut=0.5, highcut=100, fs=1000, order=4, \n          remove_powerline=True, powerline_freq=50):\n    # Handle 1D or 2D input\n    is_1d = False\n    if signal.ndim == 1:\n        signal = signal.reshape(-1, 1)\n        is_1d = True\n    \n    # Step 0: Clean input\n    signal = np.nan_to_num(signal, nan=0.0, posinf=0.0, neginf=0.0)\n    \n    # ===== STEP 1: Notch Filter (Remove power line noise) =====\n    if remove_powerline:\n        filtered = signal.copy()\n        \n        # Design notch filter\n        nyquist = 0.5 * fs\n        quality_factor = 30.0  # Narrower notch = higher Q\n        \n        # Create notch filter coefficients\n        b_notch, a_notch = iirnotch(powerline_freq, quality_factor, fs)\n        \n        # Apply notch filter to each channel\n        for i in range(filtered.shape[1]):\n            filtered[:, i] = filtfilt(b_notch, a_notch, filtered[:, i])\n    else:\n        filtered = signal.copy()\n    \n    # ===== STEP 2: Bandpass filter (0.5-100 Hz) =====\n    nyquist = 0.5 * fs\n    low = lowcut / nyquist\n    high = highcut / nyquist\n    \n    # Ensure normalized frequencies are in valid range (0, 1)\n    low = max(low, 0.001)\n    high = min(high, 0.999)\n    \n    # Design bandpass filter\n    b, a = butter(order, [low, high], btype='band')\n    \n    # Apply bandpass filter to each channel\n    bandpassed = np.zeros_like(filtered)\n    for i in range(filtered.shape[1]):\n        bandpassed[:, i] = filtfilt(b, a, filtered[:, i])\n    \n    # ===== STEP 3: Median filter to estimate baseline (200ms window) =====\n    baseline = np.zeros_like(bandpassed)\n    kernel_size = 201  # Must be odd number\n    \n    for i in range(bandpassed.shape[1]):\n        baseline[:, i] = medfilt(bandpassed[:, i], kernel_size=kernel_size)\n    \n    # ===== STEP 4: Subtract baseline =====\n    baseline_corrected = bandpassed - baseline\n    \n    # ===== STEP 5: Linear detrending (remove any residual drift) =====\n    detrended_signal = detrend(baseline_corrected, axis=0, type='linear')\n    \n    # ===== STEP 6: Final centering =====\n    result = detrended_signal - np.mean(detrended_signal, axis=0, keepdims=True)\n    \n    # Clean output\n    result = np.nan_to_num(result, nan=0.0, posinf=0.0, neginf=0.0)\n    \n    # Return in original format\n    if is_1d:\n        return result.flatten()\n    else:\n        return result\ndef Wavelet(signal, lowcut=0.5, highcut=100, fs=1000, order=4, \n          remove_powerline=True, powerline_freq=50, use_wavelet=True, \n          wavelet='sym10', wavelet_level=6, denoise=True): \n    # Handle 1D or 2D input\n    is_1d = False\n    if signal.ndim == 1:\n        signal = signal.reshape(-1, 1)\n        is_1d = True\n    \n    # Step 0: Clean input\n    signal = np.nan_to_num(signal, nan=0.0, posinf=0.0, neginf=0.0)\n    \n    # ===== STEP 1: Notch Filter (Remove power line noise) =====\n    if remove_powerline:\n        filtered = signal.copy()\n        \n        # Design notch filter\n        nyquist = 0.5 * fs\n        quality_factor = 30.0  # Narrower notch = higher Q\n        \n        # Create notch filter coefficients\n        b_notch, a_notch = iirnotch(powerline_freq, quality_factor, fs)\n        \n        # Apply notch filter to each channel\n        for i in range(filtered.shape[1]):\n            filtered[:, i] = filtfilt(b_notch, a_notch, filtered[:, i])\n    else:\n        filtered = signal.copy()\n    \n    # ===== STEP 2: Bandpass filter (0.5-100 Hz) =====\n    nyquist = 0.5 * fs\n    low = lowcut / nyquist\n    high = highcut / nyquist\n    \n    # Ensure normalized frequencies are in valid range (0, 1)\n    low = max(low, 0.001)\n    high = min(high, 0.999)\n    \n    # Design bandpass filter\n    b, a = butter(order, [low, high], btype='band')\n    \n    # Apply bandpass filter to each channel\n    bandpassed = np.zeros_like(filtered)\n    for i in range(filtered.shape[1]):\n        bandpassed[:, i] = filtfilt(b, a, filtered[:, i])\n    \n    # ===== STEP 3: WAVELET TRANSFORM (NEW - Baseline removal + Denoising) =====\n    if use_wavelet:\n        wavelet_result = np.zeros_like(bandpassed)\n        \n        for i in range(bandpassed.shape[1]):\n            channel = bandpassed[:, i]\n            \n            # Perform wavelet decomposition\n            coeffs = pywt.wavedec(channel, wavelet, level=wavelet_level)\n            \n            # Remove baseline by zeroing approximation coefficients (cA)\n            # This removes very low frequency components (baseline wander)\n            coeffs[0] = np.zeros_like(coeffs[0])\n            \n            # ===== Soft thresholding for denoising =====\n            if denoise:\n                # Calculate threshold using MAD (Median Absolute Deviation)\n                # Focus on highest frequency details (cD1) to estimate noise\n                detail_coeffs = coeffs[-1]\n                sigma = np.median(np.abs(detail_coeffs)) / 0.6745\n                threshold = sigma * np.sqrt(2 * np.log(len(channel)))\n                \n                # Apply soft thresholding to all detail coefficients\n                # This removes high-frequency noise while preserving ECG features\n                for j in range(1, len(coeffs)):\n                    coeffs[j] = pywt.threshold(coeffs[j], threshold, mode='soft')\n            \n            # Reconstruct signal from modified coefficients\n            reconstructed = pywt.waverec(coeffs, wavelet)\n            \n            # Handle length mismatch (wavelet reconstruction might be slightly longer)\n            if len(reconstructed) > len(channel):\n                reconstructed = reconstructed[:len(channel)]\n            elif len(reconstructed) < len(channel):\n                pad_length = len(channel) - len(reconstructed)\n                reconstructed = np.pad(reconstructed, (0, pad_length), mode='edge')\n            \n            wavelet_result[:, i] = reconstructed\n        \n        # Use wavelet result for next steps\n        signal_to_denoise = wavelet_result\n    else:\n        # If not using wavelet, use bandpassed signal directly\n        signal_to_denoise = bandpassed\n    \n    # ===== STEP 4: Median filter to estimate baseline (200ms window) =====\n    baseline = np.zeros_like(signal_to_denoise)\n    kernel_size = 201  # Must be odd number\n    \n    for i in range(signal_to_denoise.shape[1]):\n        baseline[:, i] = medfilt(signal_to_denoise[:, i], kernel_size=kernel_size)\n    \n    # ===== STEP 5: Subtract baseline =====\n    baseline_corrected = signal_to_denoise - baseline\n    \n    # ===== STEP 6: Linear detrending (remove any residual drift) =====\n    detrended_signal = detrend(baseline_corrected, axis=0, type='linear')\n    \n    # ===== STEP 7: Final centering =====\n    result = detrended_signal - np.mean(detrended_signal, axis=0, keepdims=True)\n    \n    # Clean output\n    result = np.nan_to_num(result, nan=0.0, posinf=0.0, neginf=0.0)\n    \n    # Return in original format\n    if is_1d:\n        return result.flatten()\n    else:\n        return result","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-11T14:31:25.445066Z","iopub.execute_input":"2025-11-11T14:31:25.445421Z","iopub.status.idle":"2025-11-11T14:31:25.470581Z","shell.execute_reply.started":"2025-11-11T14:31:25.445389Z","shell.execute_reply":"2025-11-11T14:31:25.469475Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"sample_ids=f_train[\"record_id\"].unique()\nfor i in sample_ids:\n    sample_data=f_train[f_train[\"record_id\"]==i].copy()\n    sample_data.drop(\"record_id\", axis=1, inplace=True)\n    signal = sample_data[[\"AECG1\",\"AECG2\",\"AECG3\",\"AECG4\"]].values[0:]\n    filtered1 = bandPass(signal, 0.5, 100, recordA.fs)\n    filtered2 = newBP(signal, 0.5, 100, recordA.fs)\n    filtered3 = Wavelet(signal, 0.5, 100, recordA.fs)\n    fig, axes = plt.subplots(4, 4, figsize=(22, 14))\n    \n    channel_names = [\"AECG1\", \"AECG2\", \"AECG3\", \"AECG4\"]\n    method_names = [\n        \"Original Signal\",\n        \"Bandpass Only\\n(0.5-100 Hz)\",\n        \"Notch + Bandpass\\n(50 Hz removed)\",\n        \"Notch + BP + Wavelet\\n(Complete Pipeline)\"\n    ]\n    colors = [\"black\", \"blue\", \"red\", \"green\"]\n     # Plot for each channel (rows)\n    for ch in range(4):\n        # Row label (channel name) on the left\n        axes[ch, 0].text(-0.38, 0.5, channel_names[ch], \n                        transform=axes[ch, 0].transAxes,\n                        fontsize=14, fontweight='bold', \n                        verticalalignment='center', \n                        rotation=90,\n                        bbox=dict(boxstyle='round', facecolor='lightgray', alpha=0.8))\n        \n        # Plot for each filtering method (columns)\n        for method in range(4):\n            ax = axes[ch, method]\n            \n            # Select appropriate data based on method\n            if method == 0:  # Original\n                data = signal[:, ch]\n                color = colors[0]\n                alpha = 0.75\n            elif method == 1:  # Bandpass only\n                data = filtered1[:, ch]\n                color = colors[1]\n                alpha = 0.8\n            elif method == 2:  # Notch + Bandpass\n                data = filtered2[:, ch]\n                color = colors[2]\n                alpha = 0.8\n            else:  # Notch + Bandpass + Wavelet (complete)\n                data = filtered3[:, ch]\n                color = colors[3]\n                alpha = 0.8\n            \n            # Plot signal\n            ax.plot(data, color=color, linewidth=0.8, alpha=alpha)\n            ax.axhline(y=0, color='red', linestyle='--', linewidth=0.5, alpha=0.3)\n            ax.grid(True, alpha=0.3)\n            ax.set_xlim(0, 10000)\n\n            if ch == 0:\n                ax.set_title(method_names[method], \n                           fontsize=11, fontweight='bold', pad=10,\n                           bbox=dict(boxstyle='round', facecolor='lightyellow', alpha=0.7))\n            \n            # Set x-label (only on bottom row)\n            if ch == 3:\n                ax.set_xlabel('Sample Index', fontsize=10)\n            else:\n                ax.set_xticklabels([])\n            \n            # Set y-label for first column\n            if method == 0:\n                ax.set_ylabel('Amplitude (µV)', fontsize=10, fontweight='bold')\n            else:\n                ax.set_yticklabels([])\n\n    fig.suptitle(f'Complete Filtering Pipeline Analysis - Sample {i}\\n' + \n                 f'4 Channels × 4 Processing Methods (10,000 samples = 10 seconds)', \n                fontsize=15, fontweight='bold', y=0.995)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-11T14:31:31.821248Z","iopub.execute_input":"2025-11-11T14:31:31.822184Z","iopub.status.idle":"2025-11-11T14:35:02.668823Z","shell.execute_reply.started":"2025-11-11T14:31:31.822154Z","shell.execute_reply":"2025-11-11T14:35:02.667386Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def process_batch(records, batch_name, path_A):\n    print(f'\\n {batch_name}: {len(records)}')\n    batch_data=[]\n    for idx, record in enumerate(records):\n        print(f\"[{idx+1}/{len(records)}] {record}...\", end=' ')\n        \n        try:\n            path = os.path.join(path_A, record)\n            rec = wfdb.rdrecord(path)\n            signal = rec.p_signal\n            \n            filtered = Wavelet(signal, lowcut=0.5, highcut=100, fs=1000, order=4,\n                             remove_powerline=True, powerline_freq=50, use_wavelet=True,\n                             wavelet='sym10', wavelet_level=6, denoise=True)\n            \n            ann = wfdb.rdann(path, 'fqrs')\n            qrs_peaks = set(ann.sample)\n            \n            df = pd.DataFrame(filtered, columns=['AECG1','AECG2','AECG3','AECG4'])\n            df['record_id'] = record\n            df['sample_index'] = range(len(df))\n            df['qrs_peak'] = [1 if i in qrs_peaks else 0 for i in range(len(df))]\n            batch_data.append(df)\n            print(f\"✓ {df['qrs_peak'].sum()} QRS\")\n            \n            del rec, signal, filtered, df\n            gc.collect()\n            \n        except Exception as e:\n            print(f\"✗ {e}\")\n\n    batch_df = pd.concat(batch_data, ignore_index=True)\n    print(f\"{batch_name}\")\n    return batch_df","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-11T14:35:02.670467Z","iopub.execute_input":"2025-11-11T14:35:02.670759Z","iopub.status.idle":"2025-11-11T14:35:02.681285Z","shell.execute_reply.started":"2025-11-11T14:35:02.670732Z","shell.execute_reply":"2025-11-11T14:35:02.680193Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"batch1=process_batch(records_A[0:25], \"BATCH 1\", path_A)\nbatch1.to_csv(\"/kaggle/working/batch_1.csv\")\nprint(\"Saved BATCH 1\")\n\nbatch2=process_batch(records_A[25:50], \"BATCH 2\", path_A)\nbatch2.to_csv(\"/kaggle/working/batch_2.csv\")\nprint(\"Saved BATCH 2\")\n\nbatch3=process_batch(records_A[50:75],\"BATCH 3\", path_A)\nbatch3.to_csv(\"/kaggle/working/batch_3.csv\")\nprint(\"Saved BATCH 3\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-11T14:35:02.682278Z","iopub.execute_input":"2025-11-11T14:35:02.682644Z","iopub.status.idle":"2025-11-11T14:35:59.547771Z","shell.execute_reply.started":"2025-11-11T14:35:02.682615Z","shell.execute_reply":"2025-11-11T14:35:59.546743Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"batch_1=pd.read_csv(\"/kaggle/working/batch_1.csv\")\nbatch_2=pd.read_csv(\"/kaggle/working/batch_2.csv\")\nbatch_3=pd.read_csv(\"/kaggle/working/batch_3.csv\")\noutput_train=pd.concat([batch_1, batch_2, batch_3]) ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-11T14:40:30.976749Z","iopub.execute_input":"2025-11-11T14:40:30.977075Z","iopub.status.idle":"2025-11-11T14:40:35.725727Z","shell.execute_reply.started":"2025-11-11T14:40:30.977052Z","shell.execute_reply":"2025-11-11T14:40:35.724313Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"del batch_1, batch_2, batch_3\noutput_train.to_csv(\"/kaggle/working/final_train1.csv\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-11T14:40:35.727102Z","iopub.execute_input":"2025-11-11T14:40:35.727417Z","iopub.status.idle":"2025-11-11T14:41:13.577159Z","shell.execute_reply.started":"2025-11-11T14:40:35.727397Z","shell.execute_reply":"2025-11-11T14:41:13.575963Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}